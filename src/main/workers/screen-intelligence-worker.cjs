/**
 * Screen Intelligence Worker Thread
 * 
 * Runs VirtualScreenDOM in a separate thread to:
 * 1. Pre-analyze windows in the background
 * 2. Cache screen data for instant queries
 * 3. Avoid blocking the main UI thread
 * 
 * Performance Impact:
 * - Cached queries: 0.05s (vs 7.39s uncached)
 * - 41% reduction in total workflow time
 * - No UI blocking or typing lag
 */

// Mark this as a worker thread for VirtualScreenDOM
process.env.WORKER_THREAD = 'true';

const { parentPort } = require('worker_threads');
const VirtualScreenDOM = require('../services/virtualScreenDOM.cjs');
const crypto = require('crypto');

const logger = require('./../logger.cjs');
// Initialize virtual DOM in worker thread
let virtualDOM = null;
let isInitialized = false;

// Track pending phi4 requests
const pendingPredictiveRequests = new Map();
let requestIdCounter = 0;

// Callback to request analysis from main thread
function requestAnalysis(windowInfo) {
  logger.debug(`[WORKER] ðŸ“¡ Requesting analysis for: ${windowInfo.app} - ${windowInfo.title}`);
  parentPort.postMessage({
    type: 'requestAnalysis',
    windowInfo
  });
}

// Helper: Call phi4 service via main thread
async function callPhi4Service(action, payload) {
  return new Promise((resolve, reject) => {
    const requestId = `pred_${Date.now()}_${requestIdCounter++}`;
    
    pendingPredictiveRequests.set(requestId, { resolve, reject });
    
    // Request main thread to call phi4
    parentPort.postMessage({
      type: 'predictiveCacheRequest',
      requestId,
      action,
      payload
    });
    
    // Timeout after 30 seconds
    setTimeout(() => {
      if (pendingPredictiveRequests.has(requestId)) {
        pendingPredictiveRequests.delete(requestId);
        reject(new Error('Predictive cache request timeout'));
      }
    }, 30000);
  });
}

// Generate predictive cache in worker thread
async function generatePredictiveCacheInWorker(screenData) {
  try {
    logger.debug('[WORKER] ðŸ”® Starting predictive Q&A generation...');
    
    // Extract OCR text
    const fullTextElement = screenData.elements?.find(el => el.role === 'full_text_content');
    const ocrText = fullTextElement?.value || '';
    
    if (!ocrText || ocrText.length < 100) {
      logger.debug('[WORKER] â­ï¸  Insufficient text for prediction (need 100+ chars)');
      return;
    }
    
    logger.debug(`[WORKER] ðŸ“ OCR text available: ${ocrText.length} chars`);
    
    // Check if we already have predictions for this screen content
    const screenHash = crypto.createHash('md5').update(ocrText).digest('hex');
    
    // Initialize global cache if needed
    if (!global.predictiveCache) {
      global.predictiveCache = new Map();
      logger.debug('[WORKER] ðŸ†• Initialized global predictive cache');
    }
    
    // Check for existing cache
    const existingCache = global.predictiveCache.get(screenHash);
    if (existingCache && Date.now() - existingCache.timestamp < 300000) {
      const age = Math.round((Date.now() - existingCache.timestamp) / 1000);
      logger.debug(`[WORKER] âœ… Using existing predictions (${age}s old)`);
      return;
    }
    
    const startTime = Date.now();
    
    // Build query for phi4 general.answer
    const query = `Analyze this screen content and generate 5-7 likely follow-up questions a user might ask, along with answers from your knowledge.

Screen Content:
${ocrText.substring(0, 2000)}

For each question:
1. Identify the category (e.g., "AI:History", "Technology:Comparison", "Programming:Concepts")
2. Generate a natural question a user might ask
3. Provide a concise answer (2-3 sentences) from your training knowledge
4. Indicate if the answer relates to the screen content or is general knowledge
5. Provide a confidence score (0.0-1.0)

IMPORTANT: Return ONLY valid JSON, no markdown formatting or code blocks.

Format:
{
  "mainTopic": "Brief description of screen content topic",
  "predictedQuestions": [
    {
      "category": "Topic:Subcategory",
      "question": "Natural question text",
      "answer": "Concise 2-3 sentence answer",
      "relatedToScreen": true,
      "confidence": 0.9
    }
  ]
}`;

    logger.debug('[WORKER] ðŸ¤– Calling phi4 for prediction generation...');
    
    // Call phi4 via main thread using general.answer
    const result = await callPhi4Service('general.answer', {
      query,
      context: 'You are a predictive assistant that anticipates user questions. Always respond with valid JSON only, no markdown formatting.',
      options: {
        temperature: 0.3,
        max_tokens: 2000
      }
    });
    
    const generationTime = Date.now() - startTime;
    logger.debug(`[WORKER] â±ï¸  LLM generation complete (${generationTime}ms)`);
    
    // Extract response from general.answer format
    const responseText = result.data?.answer || result.answer || '';
    
    logger.debug('[WORKER] ðŸ“„ Raw LLM response length:', responseText.length);
    
    // Parse JSON response
    let predictions;
    try {
      const cleanedResponse = responseText
        .replace(/```json\n?/g, '')
        .replace(/```\n?/g, '')
        .trim();
      
      predictions = JSON.parse(cleanedResponse);
      logger.debug('[WORKER] âœ… Successfully parsed predictions');
    } catch (parseError) {
      logger.error('[WORKER] âŒ Failed to parse JSON:', parseError.message);
      return;
    }
    
    // Validate structure
    if (!predictions.predictedQuestions || !Array.isArray(predictions.predictedQuestions)) {
      logger.warn('[WORKER] âš ï¸  Invalid predictions structure');
      return;
    }
    
    // Store in global cache
    global.predictiveCache.set(screenHash, {
      predictions,
      timestamp: Date.now(),
      screenContentHash: screenHash,
      ocrTextLength: ocrText.length
    });
    
    logger.debug('[WORKER] âœ… Predictions cached successfully');
    logger.debug(`[WORKER]    Main topic: "${predictions.mainTopic}"`);
    logger.debug(`[WORKER]    Generated ${predictions.predictedQuestions.length} predicted Q&A pairs:`);
    
    predictions.predictedQuestions.forEach((pred, idx) => {
      logger.debug(`[WORKER]    ${idx + 1}. [${pred.category}] "${pred.question}"`);
      logger.debug(`[WORKER]       Confidence: ${pred.confidence}, Related: ${pred.relatedToScreen}`);
    });
    
  } catch (error) {
    logger.error('[WORKER] âŒ Failed to generate predictions:', error.message);
  }
}

async function initialize() {
  if (isInitialized) return;
  
  try {
    logger.debug('[WORKER] Initializing VirtualScreenDOM...');
    
    // Pass callback to VirtualScreenDOM
    virtualDOM = new VirtualScreenDOM(requestAnalysis);
    await virtualDOM.start();
    isInitialized = true;
    
    // Notify main thread that worker is ready
    parentPort.postMessage({
      type: 'ready',
      timestamp: Date.now()
    });
    
    logger.debug('[WORKER] VirtualScreenDOM initialized successfully');
  } catch (error) {
    logger.error('[WORKER] Failed to initialize VirtualScreenDOM:', error);
    parentPort.postMessage({
      type: 'error',
      error: error.message
    });
  }
}

// Handle messages from main thread
parentPort.on('message', async (msg) => {
  try {
    switch (msg.type) {
      case 'init':
        await initialize();
        break;
        
      case 'analysisResult':
        // Main thread has completed analysis, cache it
        if (isInitialized && virtualDOM) {
          logger.debug(`[WORKER] ðŸ“¥ Received analysis result for ${msg.windowInfo.windowId}`);
          
          // Log the full analysis data structure for debugging
          logger.debug('[WORKER] ðŸ“Š Full analysis data structure:', JSON.stringify({
            windowInfo: msg.windowInfo,
            dataKeys: msg.data ? Object.keys(msg.data) : [],
            hasPlainText: !!msg.data?.plainText,
            plainTextLength: msg.data?.plainText?.content?.length || 0,
            hasStructuredData: !!msg.data?.structuredData,
            elementCount: msg.data?.structuredData?.elements?.length || msg.data?.elements?.length || 0,
            docType: msg.data?.plainText?.docType || msg.data?.docType,
            confidence: msg.data?.structuredData?.confidence || msg.data?.confidence,
            elapsed: msg.data?.elapsed,
            timestamp: msg.data?.timestamp
          }, null, 2));
          
          // Log a sample of the plain text content
          if (msg.data?.plainText?.content) {
            const sample = msg.data.plainText.content.substring(0, 500);
            logger.debug('[WORKER] ðŸ“ Plain text sample (first 500 chars):', sample);
            if (msg.data.plainText.content.length > 500) {
              logger.debug(`[WORKER] ðŸ“ Full plain text length: ${msg.data.plainText.content.length} chars`);
            }
          }
          
          // Log structured data elements sample
          const elements = msg.data?.structuredData?.elements || msg.data?.elements;
          if (elements && elements.length > 0) {
            logger.debug('[WORKER] ðŸ—ï¸ Structured elements sample:', JSON.stringify(
              elements.slice(0, 3).map(el => ({
                type: el.type,
                text: el.text?.substring(0, 100),
                position: el.position,
                confidence: el.confidence
              })), null, 2));
            logger.debug(`[WORKER] ðŸ“Š Total structured elements: ${elements.length}`);
          }
          
          virtualDOM.cacheAnalysisResult({
            windowId: msg.windowInfo.windowId,
            ...msg.data,
            url: msg.windowInfo.url // Include URL from active-window-listener
          });
          
          // Note: cacheUpdate is sent by virtualDOM.cacheAnalysisResult() to avoid duplication
          logger.debug(`âœ… [WORKER] Analysis cached successfully for ${msg.windowInfo.windowId}`);
        }
        break;
        
      case 'query':
        // Query cached screen data
        if (!isInitialized) {
          parentPort.postMessage({
            type: 'result',
            requestId: msg.requestId,
            data: null,
            error: 'Worker not initialized'
          });
          return;
        }
        
        const cached = virtualDOM.queryCached(msg.windowId, msg.strategy || 'all');
        
        parentPort.postMessage({
          type: 'result',
          requestId: msg.requestId,
          data: cached,
          fromCache: !!cached,
          timestamp: Date.now()
        });
        break;
        
      case 'invalidate':
        // Invalidate cache for specific window
        if (isInitialized && virtualDOM) {
          virtualDOM.invalidateCache(msg.windowId);
          parentPort.postMessage({
            type: 'invalidated',
            windowId: msg.windowId
          });
        }
        break;
        
      case 'generatePredictiveCache':
        // Generate predictive cache for analyzed screen data
        if (isInitialized) {
          logger.debug(`[WORKER] ðŸ”® Generating predictive cache for ${msg.windowId}...`);
          await generatePredictiveCacheInWorker(msg.data);
        }
        break;
        
      case 'predictiveCacheResponse':
        // Response from main thread for phi4 service call
        if (pendingPredictiveRequests.has(msg.requestId)) {
          const { resolve, reject } = pendingPredictiveRequests.get(msg.requestId);
          pendingPredictiveRequests.delete(msg.requestId);
          
          if (msg.error) {
            reject(new Error(msg.error));
          } else {
            resolve(msg.result);
          }
        }
        break;
        
      case 'shutdown':
        // Clean shutdown
        if (isInitialized && virtualDOM) {
          virtualDOM.stop();
        }
        process.exit(0);
        break;
        
      default:
        logger.warn('[WORKER] Unknown message type:', msg.type);
    }
  } catch (error) {
    logger.error('[WORKER] Error handling message:', error);
    parentPort.postMessage({
      type: 'error',
      requestId: msg.requestId,
      error: error.message
    });
  }
});

// Cache updates are sent by VirtualScreenDOM.cacheAnalysisResult() directly
// No need for event emitters - single source of truth

// Handle worker errors
process.on('uncaughtException', (error) => {
  logger.error('[WORKER] Uncaught exception:', error);
  parentPort.postMessage({
    type: 'error',
    error: error.message
  });
});

process.on('unhandledRejection', (error) => {
  logger.error('[WORKER] Unhandled rejection:', error);
  parentPort.postMessage({
    type: 'error',
    error: error.message
  });
});

logger.debug('[WORKER] Screen Intelligence Worker started');
